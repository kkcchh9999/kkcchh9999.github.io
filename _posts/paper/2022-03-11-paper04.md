---
title:  "Analysis of Smartphone I/O Characteristics - Toward Efficient Swap in a Smartphone 번역"
excerpt:  "효율적인 스왑을 위한 스마트폰 I/O 특성 분석 논문 번역"
categories:
  - Papers
tags:
  - [android, papers]
toc: true
toc_sticky: true
sidebar: 
  nav: "docs"
---

## 논문 번역
NosLab 연구생 활동 기간동안 읽은 논문을 번역했다. 저작권을 염려하여 그림은 삽입하지 않았다.   
원 논문은 [https://ieeexplore.ieee.org/document/8815732](https://ieeexplore.ieee.org/document/8815732) 에서 찾아볼 수 있다.  
저자는 Jisun Kim, Hyokyung Bahn 이다. 

# 효율적인 스왑을 위한 스마트폰 I/O 특성 분석 
## Analysis of Smartphone I/O Characteristics - Toward Efficient Swap in a Smartphone

## Abstract 
최근의 모바일 플랫폼 기술 발전으로 인해 사람들은 스마트폰을 통해 더 많은 일을 하고 있다.
예를 들어 디지털 헬스케어, 자동차 네비게이션, 주식 거래 등은 전화 통화 뿐 아니라 스마트폰에서도 진행된다. 
하지만, 스마트폰에서 신뢰 할 수 있는 소프트웨어를 실행하기 위한 몇몇 기술적 제약이 존재한다. 
구체적으로, 현재 스마트폰은 사용 가능한 메모리 공간이 소진되면 스왑을 사용하지 않고 어플리케이션을 kill 한다. 
안드로이드에서 스왑이 불가능 하지는 않지만, 우리의 관측에 따르면 안드로이드에서 swap 을 진행하면 수많은 storage 접근이 발생하고 따라서 thrashing(쓰레싱) 상태가 된다. 
이를 해결하기 위해서, 우리는 안드로이드 스왑 I/O를 추적하여 분석하고, 두가지의 중요한 관측을 실시한다.
첫 번째는 전체 스왑 입출력의 80%를 차지하는 15%의 핫 데이터의 존재이고, 두 번째는 스왑 영역에 진입하고 다시는 사용되지 않는 50%의 콜드 데이터 존재이다.
관측을 기반으로, 우리는 안드로이드 스왑 레이어로 비휘발성 메모리를 채택하는 새로운 아키텍처를 제시한다.
구체적으로는 안드로이드 스왑 데이터 접근 구조가 쌍봉분포이기 때문에, 우리는 정밀한 admission 제어 및 교제 알고리즘을 활용해 hot 과 cold 데이터를 효율적으로 식별하고 관리한다. 
이것은 우리의 스왑 아키텍처가 제한된 정보를 가진 주 메모리 계층과 다른 요청 시간 및 빈도의 전체 정보에 액세스할 수 있기 때문에 가능하다.
실험 결과는 우리의 아키텍처가 안드로이드 스왑을 성능 하락 없이 지원한다는 것을 나타낸다.   

## I.Introduction
빠른 휴대전화 어플리케이션의 확산과 모바일 플랫폼 기술의 발전으로 인해 스마트폰은 주류의 컴퓨팅 장치가 되었다.
사람들은 점점 더 스마트폰과 태블릿을 통해 일하고 있으며, 게임, SNS, 위치 기반 서비스를 비롯한 다양한 어플리케이션이 매일 새롭게 등장한다. 
사실, 현대 스마트폰 하드웨어 스펙은 이미 노트북이나 데스크탑같은 범용 컴퓨팅 장치의 수준에 도달했다. 
예를 들어 안드로이드 레퍼런스 폰인 구글의 Nexus 6P 는 퀄컴의 스냅드래곤 TM 810, 2GHz 쿼드코어 64bit Adreno, DDR4 3GB, 그리고 eMMC 128GB로 구성되어 있고, 멀티테스킹을 진행하기에 충분하다.   

스마트폰은 더이상 개인 오락 기기가 아니고, 영상 편집, 전자은행, S/W 개발 등의 공식적인 업무도 지원된다.
따라서 데스크톱 어플리케이션은 점차 외부 키보드 또는 영상 장치를 통해 스마트폰과 호환된다.
하지만, 스마트폰 시스템은 멀티테스킹 컴퓨팅 기기라는 중요한 약점이 있다.
구체적으로, 현재 안드로이드 같은 스마트폰 플랫폼은 유저의 승인 없이도 사용 가능한 메모리가 없으면 프로세스를 종료한다.
이는 스마트폰이 개인용 오락 기기일 때에는 큰 문제가 되지 않았지만, 이제는 공적 업무를 수행하는 데에 치명적이다. 
예를 들어 음악 플레이어를 종료하는 것은 심각한 문제를 발생시키지 않지만, 큰 용량의 동영상 파일을 편집하는 중에 편집기가 종료되는 것은 큰 문제를 일으킬 수 있다.  

이 이슈를 해결하기 위해, 스마트폰은 사용자가 명시적으로 어플리케이션을 종료하기 전 까지 프로세스를 보존해야한다.
이는 스왑을 통해 실현 가능한데, 스왑(swap)은 메모리가 부족할 때 어플리케이션의 메모리를 데이터를 저장하기 위해 보조 스토리지의 일부를 메인 메모리의 확장으로 사용하는 것이다. 
비록 스왑은 전통적인 컴퓨터 시스템에서 널리 사용되고 있을지라도, 우리의 분석은 스마트폰에서의 스왑을 지원하는 것은 쉬운 문제가 아님을 나타낸다. 
특히, 스왑 기능이 추가된 안드로이드 시스템은 시스템 전반에 걸친 쓰레싱 현상이 발생하여 어플리케이션의 실행 시간을 크게 느려지게 만든다.
그럼에도 스토리지에 대한 접근은 핫 데이터의 10-15%에 극도로 치우쳐 있다는 것을 관측했다.
이런 관측을 기반으로, 우리는 안드로이드 스왑에서 비휘발성 메모리를 사용하여 스토리지에 접근하는 비율을 줄이기 위한 새로운 아키텍처를 제안한다.
특히, 우리는 효율적인 관리 기술을 사용함으로써 작은 용량의 비휘발성 메모리로도 충분히 핫 데이터에대한 접근을 흡수할 수 있다는 것을 보여준다.
실험 결과에 따르면, 우리의 아키텍처가 상당히 감소된 스토리지 접근 횟수를 보이고, 따라서 성능 감소 없이 스왑을 지원한다.  

### A. Motivational Experiments
우리의 목표는 스마트폰에서 스왑을 지원하여 스마트폰을 데스크톱이나 노트북과 같은 범용 컴퓨팅 장치처럼 만드는 것이다.
이를 위해, 우리는 안드로이드 스마트폰을 재구성하고 스왑 기반의 안드로이드를 기존의 안드로이드 시스템과 비교하여 측정한다.
그림 1은 기존의 안드로이드와 스왑을 지원하는 안드로이드에서 그들의 메모리가 충분한 수의 어플리케이션을 통해 예열된 후의 다양한 어플리케이션 실행 시간 측정을 보여준다. (실험 조건은 단락 II 와 IV 에서 자세히 설명한다.) 그림에 나타난 것 처럼, 스왑을 지원하는 것은 스마트폰의 성능을 상당히 낮춘다. 
특히 스왑을 지원할 때 어플리케이션의 실행시간은 2~5배가량 늘어난다.  

이는 스왑이 어플리케이션의 실행 시간을 20~40%만 증가시킨다는 이전의 연구와 일치하지 않는다.
하지만, 이런 연구는 두 어플리케이션을 통해 간단한 시나리오를 실행함으로 수행되었다.
즉, 주어진 파일 크기의 가상 응용 프로그램이 먼저 실행된 다음, 나머지 메모리 공간을 모두 사용하기 위해 다른 응용 프로그램이 수행되고, 실행 시간을 측정하기 위해 첫 번째 응용 프로그램이 다시 실행된다.
실제로는, 보통 오랜 시간동안 휴대폰을 재시작하지 않고 많은 어플리케이션을 실행하기 때문에 이는 실제 기기에서 일어나는 모든 현상을 설명하기 어렵다.   

이전 연구와 달리, 우리는 휴대폰이 시작되고 난 후 충분한 시간이 지난 후에 시스템 상태를 관찰한다. 
즉 시간이 지남에 따라 많은 수의 어플리케이션이 실행되고, 스왑 기능이 켜진 안드로이드에서 심각한 쓰레싱 문제가 발생하는 것을 집어냈다.    

쓰레싱의 주요 원인은 그림 1과 같이 총 실행 시간의 80%를 차지하는 I/O 시간의 증가이다. 
I/O 시간이 증가하면, I/O 스케줄링, I/O 요청에 대한 메모리 회수와 같은 CPU 작업이 수행되기 때문에 CPU 시간도 증가한다. 
그러므로 스마트폰에서 스왑을 지원하기 위해서는 이런 부정적인 영향을 완화시켜야 한다.

### B. Contributions
해당 논문의 첫 번째 기여는 다양한 어플리케이션에 스왑을 지원하는 안드로이드의 스토리지 접근을 분석하는 것이다.
우리의 분석은 스왑을 지원하는 안드로이드가 기존의 안드로이드보다 4~15배 많은 I/O를 발생시킨다는 것을 보여준다.
이는 스왑을 지원하기 위해서는 어플리케이션의 메모리 주소공간을 저장하고 검색하기 위해 추가적인 스토리지 접근이 필요한 반면, 스왑 없이 어플리케이션을 kill 하고 재시작하는 데에는 대부분의 작업이 메모리에서 동작하기 때문이다. 
또다른 흥미로운 관측 결과는 스왑으로 인한 스토리지 접근이 극단적으로 치우쳐 져 있다는 점이다.
특히, 10~15%의 상위 데이터가 스토리지 접근의 80%를 차지하고 있다.
이는 기존 안드로이드가 50~60%의 상위 데이터가 전체 스토리지 접근의 80%를 차지하는 것과는 차이가 있다.   

우리의 두번째 기여는 스왑으로 인해 생성된 수많은 스토리지 접근을 제거하기 위한 새로운 아키텍처의 설계이다.
특히 우리는 안드로이드의 스왑에서 발생하는 핫 데이터 접근을 흡수하기 위한 작은 사이즈의 비휘발성 메모리를 적용했다.
제안된 아키텍처는 관측된 안드로이드의 스토리지 접근 특성을 통해 대부분의 추가적인 스토리지 접근을 제거했다.
실험 결과에 따르면, 제안된 아키텍처는 평균 89%, 최대 93%의 스토리지 접근을 줄인다.   

또한 성능 저하 없이 스왑을 사용하기 위한 비휘발성 메모리의 사이즈를 정량화하고, 비휘발성 메모리 구조에 대한 적절한 정책을 제시한다.
스왑에서 발생하는 스토리지 접근의 대부분을 차지하는 상위 10~15% 데이터를 데이터를 정의하고 유지하는 것으로, 우리는 256MB의 작은 사이즈의 비휘발성 메모리가 추가 스토리지 접근을 제거하기에 충분하다는 것을 보여준다. 
구체적으로, 우리는 콜드 데이터의 많은 부분을 비휘발성 메모리에 삽입할 수 없도록 하는 승인 제어 정책을 채택하여 값비싼 메모리 공간이 효율적이지 않은 데이터에 의해 낭비되지 않게 보호한다.
저장 공간은 핫 데이터를 유지하는 데에 사용된다. 
실험 결과는 스왑을 사용한 안드로이드의 실행 시간이 평균 82% 향상되어 기존의 안드로이드와 비슷한 결과를 나타냈다.  

논문의 나머지는 다음과 같이 이루어 져 있다.
단락 II 는 스마트폰 어플리케이션에서 추출한 스토리지 접근 특성의 분석이다.
단락 III 는 스왑 성능을 개선하기 위해 고안된 아키텍처를 제안하고, 해당 아키텍처에 사용된 알고리즘을 제시한다.
제안된 아키텍처에 대한 실험 결과는 단락 IV에 나타난다.
마지막으로 단락 V 에는 논문의 결론을 나타낸다.

## II. Analyzing Storage Accesses In Swap-Supported Android
이 섹션은 안드로이드에서의 스왑의 오버헤드를 조사하기 위해 스마트폰 어플리케이션의 스토리지 접근을 분석한다.
이를 위해, 우리는 안드로이드 커널이 가상 메모리 스왑을 지원하도록 재구성하고, 기존의 안드로이드와 함께 스토리지 접근에 대한 로그를 수집한다. 
우리는 사용 가능한 메모리를 가득 채우고 스왑 상황을 유발하기 위해 다양한 어플리케이션을 실행함으로써 메모리를 예열한다.  

Table 1은 우리가 실행한 시나리오를 나타낸다. 
우리는 각 어플리케이션을 각각의 시나리오에서 순서대로 실행했고, 스왑의 효율성을 확인하기 위해 이를 반복했다.
각 시나리오는 충분한 수의 어플리케이션으로 구성되어 있고, 따라서 기존의 안드로이드에서 어플리케이션들은 다시 실행할 때 필수적으로 종료되고 다시 시작되지만 스왑을 지원하는 안드로이드는 어플리케이션의 메모리 데이터를 보조 스토리지에 저장하고 복원한다. 
우리의 실험 설정은 1GB DDR2-DRAM 메모리와 16GB eMMC 위의 2GB 스왑 파일을 가진 ODROID-Q로 구성되어 있다.
우리는 스왑 파일을 /mnt/sdcard/partition 에 설정했다.
표 2는 우리가 설정한 파티션의 상세 정보를 보여준다.   

그림 2는 기본 안드로이드와 스왑을 지원하는 안드로이드의 스토리지 접근 분포를 나타낸다.
그림에서 x축은 작업 시퀀스를 나타내고, y축은 logical block 의 수를 나타낸다.
파란색과 빨간색 플롯은 각각 read 와 write 작업을 나타낸다.
그림에서 나타나는 대로, 스왑이 실행되면 플롯의 수가 상당히 많아진다.
이는 스왑을 지원하는 안드로이드가 메모리가 부족할 때 스왑을 위해 스토리지 접근을 반복적으로 수행하기 때문이다.
이와 달리, 기존의 안드로이드는 메모리가 부족하면 어플리케이션을 kill 한다. 
어플리케이션의 프로세스 컨텍스트를 저장하지 않고, 보조 스토리지에서 검색하지 않기 때문에, 기존의 안드로이드는 적은 수의 스토리지 접근을 발생시킨다.   

다른 중요한 관찰은 스왑을 지원하는 안드로이드의 분포가 특정 핫 데이터 블록에 치우쳐져 있는 반면 기존의 안드로이드는 그렇지 않다는 것이다. 
특히, 메모리가 부족해지면 스왑을 지원하는 안드로이드는 data, heap, stack 영역의 Anonymous page를 교환한 다음 프로세스가 다시 활성화되면 메모리에 다시 로드한다; 이는 스왑 영역에 대한 핫 I/O를 생성한다.   

그림 3과 4는 각각 기존의 안드로이드와 스왑을 지원하는 안드로이드의 누적된 스토리지 접근의 수를 보여준다.
x 축은 접근 빈도에 따라 정렬된 접근 데이터의 퍼센테이지를 나타내고, y축은 주어진 데이터 faction에 대한 접근 비율을 나타낸다.   

예를 들어, x축의 10%는 상위 10%의 데이터를 의미하고, y축에서 상응하는 지점은 스토리지 접근 비율을 나타낸다. 
그림 3에서 나타나는 것 처럼, 기존의 안드로이드는 50~60%의 상위 데이터가 전체 스토리지 접근의 80%를 차지한다.
이는 기존 안드로이드에서 데이터 접근의 비대칭성이 상대적으로 약하다는 것을 의미한다.
이와 대조적으로, 그림 4에서는 10~15%의 상위 데이터가 80%의 스토리지 액세스의 80%를 차지한다는 것을 나타내며, 이는 스왑을 지원하는 안드로이드에서 스토리지 액세스가 일부 핫 데이터에서 발생한다는 것을 의미한다. 

사실, 이런 핫 데이터는 시스템이 정상이라면, 스왑 I/O 트레이스에 나타나지 않고 메모리에 계속 남아야 한다.
안드로이드의 bottom core는 비활성 페이지만 교체하는 회수 모듈을 가진 리눅스 커널로 구성되어있기 때문에, 스왑 트레이스에 핫 데이터가 존재하는 것은 부자연스러운 것으로 보인다.
우리는 추가로 안드로이드 스왑 트레이스를 분석했고, 핫 데이터는 몇몇 필수적인 안드로이드 서비스와 공유 라이브러리로 이루어 져 있는것을 발견했다. 
동시에 실행되는 어플리케이션의 수가 증가하면서 여유 메모리 공간을 만들기 위해 그들 또한 메모리에서 제거되고, 곧바로 다시 실행되어야 하기 때문에 다시 호출된다.
이것이 동시에 실행되는 어플리케이션이 늘어나면, 어플리케이션이 종료되어 메모리를 확보하는 스왑이 없는 기본 안드로이드와의 차이점이다.  

그림 5는 기존의 안드로이드와 스왑을 지원하는 안드로이드에서 전체 스토리지 접근의 수를 비교한 것이다.
그림에서 나타내는 것과 같이, 스왑을 지원하는 안드로이드는 평균적으로 기본 안드로이드와 비교해서 약 9배 더 많은 스토리지 접근이 일어난다. 
스왑을 지원하는 안드로이드의 경우, 상위 15%의 데이터와 나머지 데이터로 분리해서 나타냈다. 
보이는 것 처럼, 상위 15%의 데이터가 전체 스토리지 접근의 84%를 유발한다; 이는 우리가 스왑을 지원하는 안드로이드에서 상위 15%의 데이터로 인해 발생하는 스토리지 접근을 제거하면, 전체 스토리지 접근 횟수가 기존의 안드로이드와 비슷하게 도달할 것이라는 것을 의미한다.  

우리의 결론은 스왑 자체가 문제가 아니라 동시에 많은 어플리케이션이 실행될 경우 심각한 쓰레싱이 발생할 수 있다는 것이다.
한번 쓰레싱이 발생할 경우, 메모리가 소진되고 안드로이드의 핵심 부분들이 메모리에서 제거되었다가 다시 로드되는 일이 반복된다.
게다가, 우리는 안드로이드의 여유 메모리가 거의 소진되었을 때 OOM(out ouf memory killer)이 활성화 되는것을 관측했다.
OOM은 페이지 회수 모듈이 페이지 프레임을 free 시키는 것을 실패해서 시스템이 정상적으로 동작할 수 없을 때 동작한다.
이 경우, 프로세스들은 메모리 점유율과 nice 값에 따라 최소 메모리 여유공간이 남을 때 까지 kill된다.
이를 고려했을 때, 스왑을 지원하는 안드로이드는 이런 현상을 발생시키지 않는 메커니즘이 필요하다.   

지금까지 우리는 상위 15%의 안드로이드 스왑 데이터가 80%의 I/O 스왑을 구성하고, 이 때문에 쓰레싱이 발생한다는 중요한 관측을 했다. 
이 쓰레싱 문제를 해결하기 위해서, 우리는 작은 사이즈의 비휘발성 메모리(NVM, non-volatile memory)를 고속 스왑 장치로 채택했고, 핫 데이터를 이 NVM-스왑에 배치하는 것을 목표로 삼았다.  

NVM-스왑의 주된 규칙은 핫 데이터를 유지하는 것이고, NVM-스왑에 콜드 데이터가 진입하는 것을 막는 것 또한 중요하다.
이는 NVM의 용량이 제한되어 있기 때문에 MVM의 핫 데이터가 콜드 데이터에 의해 밀려날 수 있기 때문이다.   

이런 특성의 효과를 확인하기 위해, 우리는 스왑을 지원하는 안드로이드의 스토리지 접근을 단일 접근과 다중 접근으로 분류했다.
그림 6에서 나타나는 것 처럼, 단일 접근의 비중은 우리가 사용한 모든 시나리오에서 50%를 넘는다. 
단일 접근 데이터의 많은 부분은 NVM-스왑에 유지되더라도 다시 사용되지 않는다.   

그러므로, 콜드 데이터를 분류하는 것과 그들이 NVM-스왑에 접근하지 못하게 하는 것은 우리가 관측한 많은 양의 단일 접근 데이터로 NVM-스왑이 오염되는 것을 방지해서 NVM의 이점을 극대화할 수 있다.
우리의 관측에 따르면, 다시 참조될 가능성이 없는 콜드 데이터를 분류하고, NVM-스왑에 로드되는 것을 방지하는 것은 필수적이다. 
메인 메모리 시스템과 달리, 다음 장에서 설명할 admission control policy를 사용하여 NVM-스왑에서는 이러한 콜드 데이터를 효과적으로 관리할 수 있다.

## III. Supporting Swap In Smartphones
이번 단락에서는 안드로이드에서 효율적인 스왑을 지원하는 메커니즘을 설명한다.
우리는 먼저 NVM을 사용하는 새로운 아키텍처를 제시하고, 해당 아키텍처가 얼마나 효율적인지를 나타낸다.   

### A. The New Swap Architecture
단락 II 에서 진행한 관측을 바탕으로, 우리는 안드로이드에서 성능 저하 없이 가상 메모리 스왑을 지원하는 새로운 아키텍처를 제시한다. 
해당 아키텍처는 그림 7에서 나타나는 바와 같이 DRAM 메모리와 저장장치 사이에 작은 크기의 NVM을 사용한다. 
핵심 아이디어는 DRAM에서 퇴거된 핫 데이터를 PCM(phase change memory)나 STT-MRAM(spin torque transfer magnetic RAM)과 같은 NVM에 유지시키는 것이다. 
NVM 기술은 낮은 지연성과 영구 보존성을 제공한다; 이는 대기 상태에서 새로 고침 작업을 실행할 필요가 없기 때문에 DRAM에 비해 에너지 소모 또한 매우 낮다.
인텔이 발표한 특허는 컴퓨터 시스템의 스토리지 계층에서 NVM을 지원하기 위한 상세화 된 마이크로 아키텍처를 묘사하고, 이는 곧 NVM의 시대가 다가옴을 의미한다.
하지만, nvm은 가격과 성능적인문제 때문에 DRAM을 대체하기보다는, 성능 향상을 위한 추가 구성 요소로 고려된다.  

이 논문에서 우리는 효율적인 관리 기술을 채택한 스왑을 지원하는 안드로이드에서 추가적으로 발생하는 스토리지 접근을 제거하기 위해 작은 용량의 NVM으로 충분하다는 것을 보여준다. 
시스템에 여유 메모리가 충분하지 않을 때, 스왑을 지원하는 안드로이드는 최근에 사용되지 않은 메모리 데이터의 일정한 수를 선택하고, DRAM에서 내보낸다.
만일 추방된 데이터가 DRAM에서 최근에 수정되었다면, 해당 데이터는 메모리에서 내보내기 전에 스토리지에 먼저 쓰여진다.
이 논문에서는 스토리지 대신에 NVM이 임시적으로 메모리에서 내보내진 데이터를 유지한다.
그러므로, 스토리지 접근이 요구되면, 스토리지보다 NVM에서 먼저 해당 데이터를 보유중인지 확인된다.
만약 요청된 데이터가 NVM 에서 나타난다면, 해당 데이터는 스토리지 접근 없이 DRAM으로 로드된다.   

### B. Optimized Adoption of Non-Volatile Memory
현재로는, NVM의 용량이 제한되어 있고, 효과적인 관리 기술이 필요하다.
만일 NVM에 여유 공간이 필요하다면 데이터를 스토리지로 flush 할 교체 정책이 필요하다. 
DRAM과 다르게, 우리는 NVM에서 복잡한 알고리즘을 채택할 수 있다.
메인 메모리 시스템은 각 메모리에 접근하는 시간을 정확히 알 수 없고, 대신 단편적인 정보(ex: 최근에 접근 했는지 아닌지를 나타내는 바이너리)만을 가지고, 따라서 DRAM의 교체 정책은 대체로 단순하다.
예를들어, 인기있는 CLOCK 알고리즘은 각 데이터가 최근에 접근했는지 아닌지를 나타내는 하나의 비트를 사용하고, 해당 비트가 0이라면 데이터를 내보낸다.
반면에, 우리의 NVM은 DRAM의 데이터가 제거되었을 때만 요청을 처리하고, 요청에 대한 빈도, 시간 등의 모든 정보를 알고있다.
따라서 우리는 최근에 LRU(Least Recently Used)나 LFU(Least Frequency Used)등의 더 복잡한 알고리즘을 사용할 수 있다.   

NVM의 주요한 문제는 스토리지 접근의 대부분을 차지하는 핫 데이터를 식별하는 것이고, NVM을 통해서 이를 흡수하는 것이다.
해당 과정에서, 콜드 데이터가 한정된 용량의 NVM에서 핫 데이터를 밀어낼 수 있기 때문에 콜드 데이터를 식별하고 분류하는 것 또한 중요하다.
특히, 10~15%의 핫 데이터가 80%의 스토리지 접근을 차지하는 것은 그림 4에서 나타냈고, 이는 85~90%의 콜드 데이터가 전체 접근의 20%를 차지하는 것을 의미한다.
추가로, 우리는 50% 이상의 단일 접근 데이터가 안드로이드에서 스왑 I/O에서 존재한다는 것을 그림 6에서 나타냈다. 
이 많은 양의 콜드 데이터는 NVM에서 제거되기 전까지 다시 사용되지 않기 때문에 성능 향상에 도움이 되지 않는다.
이는 NVM이 DRAM 메모리에서 데이터를 내보낼 때만 요청을 받는 두 번째 메모리이기 때문에 발생한다.
특히, 시스템의 working-set이 NVM의 용량 밖에 있을때, NVM의 과도하게 빈번한 교체를 발생시키는 쓰레싱이 발생한다.
일반적으로, 비록 해당 데이터가 추후에 사용될지 모르더라도, 요구되는 모든 데이터를 메모리에 저장해서 성능이 향상되기를 기대할 수 있다.
하지만 단락 II에서도 언급했듯, 이 경우에는 NVM의 크기가 제한되어있어 크기가 큰 콜드 데이터를 받아들이기를 기대할 수 없다.   

이런 관측을 바탕으로, 우리는 데이터를 평가해서 재사용할 것 같지 않은 데이터는 NVM에 들어가는 것을 금지하는 Addmission Control(AC) 정책을 제안한다.
특히, 우리는 첫 번째 DRAM에서의 데이터 방출때 NVM에 데이터를 삽입하지 않고, 일정 시간 내에 두 번째 데이터 방출 이후에 NVM에 데이터를 삽입한다.
이를 통해 NVM에 들어가는 데이터를 필터링하고 메모리가 오염되는것을 막고, 성능을 향상시킨다.   

정해진 시간을 유지하기 위해 작은 histroy 버퍼를 사용한다.
이 버퍼는 실제 데이터를 저장하지는 않고 최근에 DRAM에서 데이터가 방출되었는지에 대한 정보를 유지한다.
history 버퍼의 최적의 크기는 워크로드의 특성 뿐 아니라 실제 NVM의 크기에도 영향을 받으며 다양하다. 따라서 이는 조정할 수 있는 변수이다.
기본으로, 우리는 history buffer의 수를 NVM의 실제 데이터 수로 설정했다.
이는 합당한데, 왜냐하면 우회된 데이터 자체는 저장되지 않지만, 해당 데이터가 정해진 시간 내에 다시 사용될지 여부를 확인하기 위한 기록은 유지되기 때문이다.
history buffer은 매우 작은 부담을 갖는데, 이는 메타데이터의 작은 사이즈만 유지하기 때문이다. 실제 데이터가 4KB 일 때 메타데이터의 크기는 각 데이터당 20 byte 미만이다   

이제, AC정책의 설명으로 돌아가자.
해당 정책의 모티브는 전체의 85~90%의 크기를 차지하지만, 실제 스토리지 접근은 20%보다 적은 콜드 데이터의 존재이다. 
따라서, 두 번째 데이터 방출은 데이터가 근미래에 효과적일지의 여부에 대한 좋은 지표이다. 
우리의 AC 정책의 이점은 현재의 working-set보다 NVM의 용량이 작을 때 비싼 NVM 공간을 적합하지 않은 데이터로 오염되는 것을 막아주는 것이다.
저장 공간은 핫 데이터를 오래 유지하는 데에 사용될 수 있고, 따라서 빈번한 교체를 예방할 수 있다.   

## IV. Performance Evauations
본 단락에서는, NVM을 사용한 스왑을 지원하는 안드로이드 아키텍처의 효과를 확인하기 위한 성능평가 결과를 나타낸다.   

우리는 해당 실험을 안드로이드 레퍼런스 기기에서 실행했다: ODROID-Q
이는 1GB 의 DDR2-DRAM 메모리와 2GBd의 스왑파일을 포함한 16GB의 eMMC를 가진다. 
우리는 구글 안드로이드 6.0.1과 리눅스 3.4.0을 설치했고, 안드로이드 커널을 가상 메모리 스왑을 지원하도록 재구성했다. 
실험에서는 어플리케이션의 실행 시간을 확인하기 위해서, 그리고 교체 및 AC 알고리즘에 대한 효과를 조사하기 위해서 측정이 수행되었다.
우리가 시뮬레이션을 사용하는 이유는 실제 트레이스를 사용한 시뮬레이션이 어플리케이션 실행마다 동일한 조건으로 실제 워크로드를 반복할 수 있기 때문에 매번 실제 워크로드를 직접 실행하는 것 보다 더 공정하게 비교할 수 있기 때문이다. 
이는 워크로드가 실행되는 각 워크로드에 대해 동일한 사용자 상호 작용 및 시스템 상태로 실행될 수 없어 공정한 비교가 어렵지만, 시뮬레이션은 동일한 조건을 반복할 수 있기 때문이다. 
측정에서는 각 시나리오의 실행을 10회 반복하고 각 실행의 평균 시간을 기록했다.
시뮬레이션에서는 각 시나리오가 실행되는 동안 I/O 트레이스를 추출한 후에 이를 다시 재생함으로 트레이스 기반 시뮬레이션을 실행했다.  

### A. Sensitivity Analysis On The Non-Volatile Memory Size
우리는 스왑을 지원하는 안드로이드의 스토리지 I/O 트레이스를 수집하고 트레이스 기반의 시뮬레이션을 수행했다. 
해당 시뮬레이션에서 사용된 스토리지 I/O는 안드로이드 커널의 ftrace utility에서 추출되었다. 
우리의 실험에서, 블록의 크기는 대부분의 OS처럼 4KB로 설정되었다. 
실험에서 사용된 트레이스는 20개의 안드로이드 어플리케이션이 실행되는고 있는 중에 수집되었다.
네개의 시나리오가 있고, 각 시나리오에는 표 1에 나타나는 다섯개의 어플리션을 포함한다.
우리는 각 시나리오의 어플리케이션을 순차적으로 실행했고, 스왑의 효과를 보기 위해 반복했다.   

그림 8은 NVM의 크기가 2MB에서 2048MB 까지 다양할 때의 시뮬레이션 결과를 보여준다. 
NVM에 데이터 삽입이 필요하지만 필요 공간이 없을 때, 우리는 캐시에서 가장 흔하게 사용하는 LRU를 사용하여 NVM의 데이터를 방출했다.
또한, 비교를 위해 NVM의 메모리 공간이 부족할 때 우리는 다른 정책으로 LFU를 사용했다.
기존의 안드로이드는 해당 두 정책에 의해 검증되고 비교되었다.
그림에서 나타나는 것 처럼, NVM의 크기가 32MB 미만일 경우, 스왑을 지원하는 안드로이드에는 스토리지 접근이 지나치게 많다.
하지만, 32MB 보다 NVM의 크기가 커지면 두 정책간의 차이가 명백하게 나타난다. 
특히, 크기가 32MB ~ 256MB 일 때 시나리오에 상관없이 LRU의 결과가 LFU를 능가한다. 
마지막으로, 크기가 1024MB를 넘어서면 두 정책의 결과가 같아지고, 기존의 안드로이드보다 성능이 좋아진다. 
이는 NVM의 용량이 충분히 모든 데이터를 유지할 만큼 커졌기 때문이다. 
NVM의 크기를 최대한 작게 사용하는 것이 목표임으로, 우리는 LRU를 채택하고, 128~256MB의 NVM을 사용할 수 있다.
그러면 예상되는 스토리지 접근 횟수는 기존의 안드로이드와 비슷해 질 것이다.   

### B. Effectiveness of Admission Control
이제, 단락 III 에서 묘사한 우리의 접근 제어(AC, admission control) 정책의 효과를 시험해보자.
그림 9는 기존 정책과 AC 정책을 사용할 때의 스토리지 접근의 수를 나타낸다.
해당 실험에서, 우리는 주로 LRU를 채택하는데, 이는 LFU 보다 보통 성능이 좋기 때문이다.
NVM의 크기는 16~2048MB까지 다양하다. 
그림에 나타나는 대로, AC 정책을 채택했을 때 상당히 많은 스토리지 접근이 줄었다. 
특히, NVM의 크기가 128~256MB일 때 AC 정책의 효과가 명백히 나타났다.  

NVM의 크기가 충분히 클 때, AC 정책의 효과가 눈에 띄게 줄어들었다.
이는 NVM의 크기가 충분해 핫 데이터와 콜드 데이터 모두를 포함하기 때문이다. 
NVM의 크기가 매우 작을 때도 성능의 차이가 적은데, 이는 액세스 시간이 짧은 경우에만 NVM 안의 데이터가 유용하기 때문이다.
즉, NVM에 데이터가 상주하는 시간이 짧아 데이터가 재사용되기 전에 방출될 가능성이 높기 때문이다.    

해당 두 가지 극단적인 상황을 제외하고, 우리의 AC 정책은 콜드 데이터를 잘 분류하여 동작한다.
게다가, AC 정책은 NVM에 핫 데이터를 지속적으로 보존한다. 
제안한 AC 정책은 처음 DRAM 에서 데이터가 방출될 때는 데이터를 입력하지 않아서 한번의 추가적인 스토리지 접근이 발생한다.
하지만, 우리의 결과는 NVM의 크기가 충분히 크지 않아도 AC가 잘 동작하는 것을 나타내는데, 이는 콜드 데이터를 효과적으로 필터링 하는것이 메모리 관리에 효과적이라는 것을 의미한다.   

### C. Comparison of the Launch Time 
제안된 아키텍처를 추가적으로 검증하기 위해, 우리는 Section I에서 소개한 어플리케이션들(Angrybird, BBC, Chrome, Instagram, Farmstory, Cut the Rope)을 실행했고, 기존의 안드로이드, 스왑을 지원하는 안드로이드, 그리고 제안하는 아키텍처에서 실행시간을 비교했다. 
여기서 아키텍처는 256MB의 NVM을 AC 정책과 함께 채택했다. 
각 실험에서, 어플리케이션이 처음 실행되고 상당한 수의 어플리케이션이 DRAM을 채울 만큼 실행되었다; 그리고 목표 어플리케이션이 다시 실행되었다.   

그림 10은 어플리케이션의 실행 시간을 각 구조별로 비교하여 보여준다. 그림에서 볼 수 있듯, 스왑이 지원하는 안드로이드는 상당히 실행 시간이 길지만, 우리의 구조는 기존의 안드로이드와 비슷한 성능을 보여준다. 
어떠한 경우에는 우리의 구조가 기존의 안드로이드보다 나은 성능을 보이기도 한다. 
구체적으로, Chrome, Instagram, Farmstory, Cut the Rope 에서 기존의 안드로이드보다 17~40% 향상된 성능을 나타낸다. 
스왑을 지원하는 안드로이드와 비교하여 실행 시간이 평균적으로 77% 빠르다.   

### D. Discussions
이 단락에서, 우리는 관측을 요약하고 실험 결과를 간략히 논의한다.
우리는 스왑을 지원하는 안드로이드에서 실행중인 어플리케이션이 늘어날 때 심각한 쓰레싱 현상(i.e., 2~5배의 성능 저하 현상)을 관측했다.
이를 정량화하고 안드로이드에서 스왑을 효과적으로 지원하기 위해 안드로이드의 스왑 I/O를 추적하고, 두가지 중요한 관찰을 실행했다. 
첫 번째는 전체 스왑 I/O의 80%를 차지하는 15%의 핫 데이터의 존재이고, 두 번째는 50%의 콜드 데이터는 스왑 후에 다시는 재사용되지 않는다는 것이다. 
이런 관측을 기반으로 우리는 NVM-스왑을 어떻게 효율적으로 관리할 것인지 분석했다.   

안드로이드 스왑은 쌍봉분포적 특성을 가지기 때문에, 우리는 핫과 콜드 데이터를 효과적으로 식별할 필요가 있다.
그들을 메인 메모리 레이어에서 관리하는 대신, 우리는 NVM을 스왑 I/O 레이어로 채택하였고, 접근에 대한 관리로 구성된 정밀한 알고리즘을 사용했다.
이를 통해 우리는 안드로이드에서 스왑이 성능 저하 없이 효과적으로 지원 될 수 있음을 나타냈다.   

스왑 I/O 계층의 교체 정책은 하드웨어로 구성되는 on-chip 캐시 교체 정책과 달리 소프트웨어로 구성될 수 있음으로, 완전 연관 데이터 배치의 오버헤드는 크지 않다.  

해당 논문은 NVM의 내구성 문제를 고려하지 않았다. 이는 기본 메모리 또는 on-chip 캐시 엑세스에 비해 빈번하지 않기 때문이다.
PCM과 STT-MRAM의 내구성 주기는 각각 플래시 메모리보다 3~4배, 7~8배 높다. 
내구성 문제에 대해서는 다른 연구에서 참조할 수 있다.   

## V. Conclusion
해당 논문에서, 우리는 스마트폰이 범용 컴퓨터가 되기 위한 문제를 논의했다. 
우리는 현대 스마트폰에서 상당한 문제점으로 유저의 동의 없는 어플리케이션의 종료로 인해 프로세스의 context를 상실하는 것을 내세웠다.
이를 해결하기 위해, 우리는 효율적으로 현대 스마트폰에서 채택할 수 있는 가상 메모리 스왑 구조를 제시했다.
우리는 스토리지 접근에 대한 특성을 안드로이드와 스왑을 지원하는 안드로이드에서 분석했고, 중요한 두 가지 현상을 찾아냈다.
먼저, 스왑을 지원하는 안드로이드는 4~15배 많은 스토리지 접근을 수행한다. 
두 번째로, 스왑에서 발생하는 스토리지 접근은 10~15%의 핫 데이터에서 발생한다.   

해당 관측을 바탕으로, 우리는 스왑을 지원하는 안드로이드에서 빈번한 스토리지 접근을 제거한 아키텍처를 제시했다.
특히, 우리는 효과적인 관리 정책을 사용함으로써 핫 데이터를 흡수하기 위해 작은 사이즈의 NVM을 채용했다.
우리는 요구되는 NVM의 사이즈가 256MB임을 나타냈고, 이를 통해 스토리지 접근 시간과 프로그램의 실행 시간을 각각 93, 82% 감소시켰다.
