---
title:  "Continual Learning on the Edge with TensorFlow Lite 번역"
excerpt:  "TF Lite를 사용한 주변 기기에서의 연속학습 논문 번역"
categories:
  - Papers
tags:
  - [android, papers]
toc: true
toc_sticky: true
sidebar: 
  nav: "docs"
---

## 논문 번역
NosLab 인턴 활동 기간동안 읽은 논문을 번역했다. 저작권을 염려하여 그림은 삽입하지 않았다.   
원 논문은 [https://arxiv.org/abs/2105.01946](https://arxiv.org/abs/2105.01946) 에서 찾아볼 수 있다.  
저자는 Giorgos Demosthenous, Vassilis Vassiliades 이다. 

# TF Lite를 사용한 주변 기기에서의 연속학습
## Continual Learning on the Edge with  TensorFlow Lite

## Abstract 초록 
임베디드 장치에서 실제 문제를 해결하기 위한 정교한 딥러닝 모델을 사용하는 것은 현대 기술을 사용해도 무리가 있다. 
개인 프라이버시, 데이터 제한, 네트워크 연결 등의 이슈는 오늘날의 해결해야할 과제이며, 빠른 모델 적용의 필요성으로 인해 장치에서 실시간으로 학습하는 기능이 필수적이다.
구글에서는 현재 TensorFlow Lite에 전이 학습 API 를 내장해서 이 이슈를 다루고 있다. 
이 논문에서는 전이학습이 on-device 학습에 대한 좋은 접근이지만, 현실적인 시나리오에서는 전이학습이 catastrophic forgetting(파괴적 망각) 문제를 겪는다는 것을 보여준다.
해당 문제를 보여주기 위해 간단한 전이학습 어플리케이션을 CORe50 벤치마크로 테스트하고, 전이학습의 한계를 증명하기 위해 개발한 어플리케이션을 사용 한다.
추가적으로, 우리는 단순 replay 접근 방식을 현재 전이 학습 모델에 통합하는 방식으로 TensorFlow Lite 라이브러리를 확장하여 continual learning(연속학습)을 구현한다.
우리의 연속학습 모델을 CORe50 벤치마크로 테스트하여 해당 모델은 비 이상적인 조건에서도 연속학습이 가능하고, 파괴적 망각 또한 해결함을 나타낸다.
마지막으로, 우리의 어플리케이션 소스코드를 통해 개발자들이 그들의 스마트폰 어플리케이션에 연속학습을 통합하고, TF Lite 환경에서의 연속학습의 발전을 촉진시키기 위해 코드를 공개한다.   

## 1. Introduction 서론 
최근 몇년간, 정교한 딥러닝 모델을 실험실이 아닌 주변 장치들(스마트폰, 로봇 그리고 기타 임베디드 시스템들)에 적용하는 일이 증가하는 추세이다.
또한, 이 기술을 이용하여 일상 생활에서도 사용하기 위한 지속적인 노력이 있어 왔다.
오늘날, 대부분의 접근은 그들의 머신러닝 모델을 오프라인에서, 강력한 GPU를 지원하는 서버에서 학습하고, 추론 기능을 주변 장치들에 도입하는 것에 초점이 맞추어 져 있다.
이 방식은 다양한 딥러닝 어플리케이션에 적합하지만, on-device 학습을 지원해야 하는 경우가 많이 있다.
개인정보 보호, 네트워크 연결 이슈, 개인화, 빠른 적응은 왜 on-device 학습이 필수적인지를 뒷받침하는 근거가 된다.
머신러닝 플랫폼 TensorFlow 와 TensorFlow Lite를 개발한 구글은 이 증가하는 필요성을 위해 그들의 TF Lite 라이브러리에 on-device 학습 기능을 내장하기 위해 작업하고있다. 
현재의 접근은 그들이 제공하는 API를 사용하여 전이 학습을 사용하여 모델을 개인화하는 것에 초점이 맞추어 져 있다.   

전이 학습(Transfer Learning, TL)은 오직 몇몇의 샘플을 통해 새로운 클래스를 학습하는데서 높은 성능을 보여준다. 
실제로 배치되었을 때, 이는 서버로 데이터를 전송할 필요 없이 빠른 학습이 가능하다. 
전이학습을 진행할 때, 모든 추가된 클래스의 데이터가 훈련 배치에 위치해야 하는데, 그렇지 않고 새로운 클래스를 점진적으로 학습할 경우 파괴적 망각을 겪기 때문이다.
불행히도, 대부분의 실제 시나리오는 새로운 클래스가 점진적으로 나타나서 임베디드 장치에 전이학습으로 구성된 모델들은 적합하지 않다. 
연속학습은 점진적으로 계속 학습을 할 수 있고, 따라서 파괴적 망각을 해결하기 위한 방법으로 주목받고 있다. 
연속학습에 대한 검증, 벤치마킹과 평가 뿐 아니라 다양한 접근법을 가진 많은 연구가 있다.
역설적이게도, 우리가 아는 한, 임베디드 장치에 연속학습을 접목하는 연구는 매우 소수이고, 특히 휴대전화에 TF Lite를 통해 접목하는 연구는 없다.   

논문에 대한 우리의 기여는 다음과 같다 : 
- TF Lite에 간단한 replay 버퍼를 도입하는 방식으로 지속적인 학습을 API에 통합하여 TF Lite 기능을 확장한다.  
- 직접 개발한 어플리케이션에서 다양한 시나리오 상황 하에 TL과 CL모델을 사용하여 실험하고, CL의 필요성을 증명하고 TL에 비해 우수한 점을 증명한다.  
- TF Lite를 통한 연속학습의 발전을 촉진하기 위해 프로그램의 소스코드를 공개한다.   

Section 3에서 TF Lite 를 통해 TL과 CL 모델이 어떻게 구현되었는지 묘사하고, CORe50 벤치마크에서 어떻게 동작하는지 실험한다. 
추가적으로 이 모델들을 최신의 지속 학습 알고리즘인 AR1과 비교한다.
Section 4에서는 실제 시나리오에 대해 우리가 개발한 어플리케이션에의 TL과 CL이 어떻게 동작하는지를 보여준다.
마지막으로 Section 5에서는 결론을 제시하고, 향후 개발한 CL 모델이 향상되기 위한 방법을 논의한다.   

## 2. Background 연구 배경
대다수의 이미지 인식, 물체 감지 그리고 다른 컴퓨터 비전 관련 작업들은 정교한 DNN에서 수백만 장의 이미지로 장기간의 학습을 통해 이루어진다.
연산 자원 부족으로 인해 현실의 문제를 해결하기 위하여 실시간으로 새로운 데이터가 들어올 때 마다 모델을 학습하는 것은 비효율적이다.
전이학습은 이전의 지식을 통해 새로운 비슷한 문제를 해결함으로 이 이슈를 해결한다. 
특별하게도, 모델은 주로 base 와 head 로 알려진 부분으로 나누어진다.
base 모델은 비슷한 컴퓨터 비전 문제를 해결하기 위해 미리 훈련된 신경망이다.
우리의 경우, MobileNet 을 사용했는데, 임베디드 장치에서 모델을 배치하고 ImageNet 데이터셋으로 미리 학습되어 있기 때문이다.
head 신경망은 주로 간단한 fully-connected layer 그리고 softmax activation 으로 이루어지는데, 매우 한정적인 양의 데이터를 통해 새로운 클래스를 학습하기 위해 base 모델에서 추출한 특성을 사용한다.
TF Lite는 현재 실험적인 API를 제공하는데, 이는 head 신경망을 확장하고, 최종 TF 모델을 임베디드 장치에 이식할 수 있게 한다.
이 TF Lite의 유연성은 기타 장치에서 바로 연속학습의 능력과 한계를 실험하기에 이상적이다.
head 신경망은 아키텍처 기반 방법, 정규화 접근 방식, 메모리 기반 시스템 및 메타 학습과 같은 잘 알려진 CL 접근 방식의 더 가벼운 버전을 용이하게 하도록 변경될 수 있다.  

이 논문에서는 그림 1에서 나타내는 간단한 replay 버퍼를 통합하여 head 신경망을 확장한다.
안드로이드 장치에서 모델을 테스트 하기 전에, 먼저 AR1 + Latent Replay(AR1 LR) 연속학습 알고리즘과 비교했다. 
AR1 LR은 연속학습을 위한 아키텍처, 정규화 및 메모리 접근 방식을 결합한 최첨단 연속 학습 알고리즘이다.
이는 수정된 MobileNet을 사용하고, 또한 ImageNet을 통해 미리 학습되어 있다.
모델 비교 및 평가를 위해 CORe50 데이터셋을 사용했고, 이는 짧은 비디오에서 추출된 50가지의 다른 물체 클래스로 구성되어 있다.
특히, 우리는 NICv2(New Instances and Classes) 시나리오를 벤치마크에서 사용했는데, 이는 새로운 클래스가 점진적으로 id가 없는 적은 배치로 학습되는 실제 상황을 완벽히 캡슐화했기 때문이다. 
새로운 클래스 및 클래스 인스턴스는 시간이 지남에 따라 391개의 배치로 모델에 점진적으로 나타난다. 
모델의 정확성은 각 학습 배치 후에 평가되어 지속적으로 학습할 수 있는 능력을 검사한다.   

CORe 어플리케이션은 AR1 LR 알고리즘의 안드로이드 구현이고, pool6 레이어에 replay 버퍼가 내재된다. 
이는 Caffe를 사용해서 안드로이드와 C++을 위해 크로스컴파일 되었다. 
이는 500가지 패턴을 replay 버퍼에 저장하고, 사용자가 5개의 새로운 클래스를 추가할 수 있다. 
샘플이 캡처되거나 replay되면 전체 신경망이 학습될 수 있고, 따라서 지속적으로 조정하고 정확도를 높일 수 있지만, 계산 오버헤드의 단점이 존재한다.
반면, 우리가 개발한 연속학습 어플리케이션은 오직 head 모델만 훈련하고, 정확도가 낮아지는 대신 시간 효율성이 높아지고 계산 오버헤드가 낮아진다.
향후에는 head의 네트워크에서 표현을 조정할 수 있도록 확장할 예정이다. 
현재 개발한 어플리케이션은 오직 40가지 패턴을 replay 버퍼에 저장하고, 사용자가 4개의 클래스를 추가할 수 있도록 한다.
구현을 위해 TF Lite를 사용하는 것은 우리의 코드와 모델이 CORe와 다르게 임베디드 장치에서 실행되는데 최적화 되었다는 것을 의미한다.
또한 이는 우리의 프로젝트가 다른 안드로이드 어플리케이션에 확장하고, 복제하고, 구현하기 쉽게 만든다.

## 3. Enhancing TensorFlow Lite Capabilities with Continual Learning
TF Lite에 CL을 확장하기 전에, 우리는 먼저 일반적인 전이학습 모델이 CORe50 NICv2 시나리오에서 어떻게 동작하는지 알아야 한다. 
TL 모델의 base 모델은 MobileNet으로 구성되어있고, head에는 간단한 하나의 fully-connected 레이어와 쌍을 이루는 softmax 활성화로 이루어 져 있다.
MobileNet의 Batch Normalization(배치 정규화) 계층을 [15]에서와 같이 지속적인 학습을 용이하게 하기 때문에 Batch Renormalization(배치 재규격화)[8]로 교체한다.
그림 2에서 묘하사는 바와 같이 전이 학습은 점진적으로 학습 데이터가 증가할 때 이전에 학습된 내용을 망각하는 것으로 보인다. 따라서 시간이 지남에 따라 정확도가 7% ~ 20% 사이로 낮다. 
그러므로, 이는 더 현실적인 시나리오를 위해 임베디드 장치에 사용할 모델을 개선할 여지가 많은것이 분명하다.  

우리는 TF Lite의 지속적인 학습 통합을 위해 몇 가지 수정을 가한 리허설 접근법을 구현하기로 결정했다.
CL 모델의 추상화된 아키텍처는 그림 1에 나타난다.
우리는 TL과 동일한 모델을 사용했지만, 헤드에 replay 버퍼가 추가되었다.
전체 영상 샘플을 버퍼에 저장하는 대신 base 모델에서 추출한 특징 패턴을 저장한다.
해당 방식을 통해 구현된 모델은 샘플을 replay하고 저장할 때 훨씬 적은 자원을 사용한다. 
우리는 head의 fully-connected 레이어에 128개의 뉴런, SGD 옵티마이저 그리고 ReLU 활성화 함수를 사용했다.
CORe50 벤치마크에서 각 배치의 훈련이 끝난 후에, 버퍼의 각 샘플이 head 모델에서 다시 replay된다.
replay 버퍼가 가득 차면, 우리는 1.5%의 현재 샘플을 새로운 것과 교체한다.    

최초에, 우리는 FIFO를 사용하여 버퍼의 특성을 교체했지만, 대략 100개의 훈련 배치 이후로 연속학습을 실패했다. 
이는 replay 버퍼에 각 클래스별 적절한 representation이 없어서 일어난 일 같다. 
FIFO 방식에서 랜덤하게 버퍼의 특성을 교체하는 방식으로 이 이슈를 해결했고, 이는 그림 3에 나타난다.
replay 버퍼에서 더 나은 클래스 표현과 더 정교한 샘플 교체 방법을 보장하면 CL 모델의 성능이 더욱 향상될 가능성이 높지만, 현재 이 논문의 범위를 벗어나 향후 작업을 위해 남겨져 있다.   

우리는 replay 버퍼의 크기와 정확도 간의 관계를 증명하기 위한 연속된 실험을 진행했고, 이는 그림 4에 나타난다.
7500 특성 패턴의 버퍼를 가지는 것이 이 벤치마크 시나리오에서 가장 좋은 균형을 이루었고, 이는 30000 버퍼에 비해 75% 적은 스토리지를 가지는 반면 정확도는 3.5%밖에 차이나지 않기 때문이다. 
그림 2에 나타난대로, replay 버퍼를 TL 모델의 head에 통합하는 것은 배치된 TF Lite 모델에 연속학습 기능을 제공하는 좋은 첫 번째 단계이다.  

우리는 AR1 LR을 우리 모델의 upper bound 로 사용한다. 
MobileNet의 가장 낮은 레이어(pool6)에서 잠재 replay 버퍼를 낮추면 이 모델이 우리의 모델과 비교할 수 있다.
이 경우, 표 1에 나타난 것 처럼 우리는 AR1 LR에 근접한 정확도를 성달성했고, 이는 우리의 모델이 충분히 잘 동작하고 임베디드 시스템에 내재할 준비가 되었다는 것을 의미한다.   

## 4. Deploying on Embedded Devices with TensorFlow Lite 
실제 시나리오에서 TL 과 CL 모델들의 성능을 비교하기 위해 삼성의 Galaxy S10에 TensorFlow Lite를 사용해서 두 모델을 탑재했다. 
특별히, 우리는 TensorFlow의 실험적 기능으로 제공하는 모델 개인화 예제의 전이학습 API를 사용했다.
우리는 연속학습 기능을 제공하기 위해 그들의 API와 예제 프로그램 모두를 확장했고, CL 과 TL 모델을 비교했다.
어플리케이션 내부에서, 유저는 4개의 다른 클래스 샘플을 카메라를 통해 추가할 수 있다.
이 샘플들은 사용자가 테스트하려는 시나리오에 따라 두 모델을 일괄적으로 또는 점진적으로 훈련하는 데 사용할 수 있다.
이 어플리케이션의 추론 결과는 그림 7에서 볼 수 있다. 
APK와 소스코드는 [GitLab page](https://gitlab.com/riselear/public/continual-learning-on-the-edge-with-tensorflow-lite)에서 찾아볼 수 있다. 

### 4.1 Expermenting with Different Scenarios
TL 모델에 비해 CL 모델의 성능과 강점을 증명하기 위해, 우리는 세가지 다른 시나리오를 실험에 포함했다: 
- `Cumulative Scenario - Batch Training: `이 시나리오에서, 우리는 그림 5 First Instance행에 보이는 각 4가지의 클래스에 50가지의 샘플을 추가했다.
샘플을 수집하는 동안, 위치와 회전은 캡쳐 범위 내에서 변화했다.
그리고 우리는 모든 200개의 샘플을 그들의 성능을 계산하기 위해 학습시켰다. 
이 시나리오에서, 0개의 샘플이 CL 모델에서 replay되었다.  
- `New Instance Scenario- Batch Training: `누적 Scenario에서 처럼 우리는 50개의 샘플을 각각의 클래스에 추가하고, 200 샘플 모두를 사용해 모델을 학습시켰다. 
replay 버퍼는 각 클래스별로 10개의 랜덤 샘플로 채워졌다. 
이후 우리는 그림 5의 Second Instance 행에 보이는 새로운 인스턴스를 각각의 클래스에 추가했다. 
각 클래스에 새로운 인스턴스를 사용한 20개씩의 샘플을 추가하고 난 후, 우리는 각 모델을 80개의 샘플로 학습시키고, CL 모델은 버퍼에 있는 40개의 샘플을 replay한다.
우리는 각 클래스의 첫 번째 인스턴스를 기억하는 능력에 의해 TL 및 CL 모델의 성능을 평가한다.   
- `New Classes Scenario - Incremental Training: `새로운 클래스 시나리오는 배포된 모델의 자연스러운 설정 및 사용과 가장 유사하다.
이 경우, 우리는 모델에 새로운 클래스를 점진적으로 도입한다.
이전 시나리오와 달리 한 클래스에 50개의 샘플을 추가하고 다음 클래스로 이동하기 전에 두 모델을 모두 학습한다.
새 클래스가 도입될 때마다 버퍼에 이미 있는 이전 샘플이 CL 모델로 재생되고 이후 새 클래스의 랜덤 샘플 10개가 replay 버퍼에 추가된다.
우리는 두 모델이 네 가지 클래스 모두에 대해 점진적으로 훈련할 때까지 반복한다.
그런 다음 추론 중에 그림 5의 First Instance 행에 표시된 객체를 분류하는 능력에 따라 TL 및 CL 모델을 평가한다.   

각 시나리오에 해당하는 모든 훈련과 검증 과정은 [demonstration video](https://www.youtube.com/watch?v=OUvWhQouSu8)에서 볼 수 있다. 

Cumulative 시나리오와 같이 훈련 중에 모든 데이터가 사용 가능할 때, CL, TL 두 모델 모두 제한된 수의 데이터를 사용하는 학습과 분류에서 문제가 없어야 한다. 
이 경우 replay 버퍼가 사용되지 않기 때문에 두 모델 모두 각 클래스에 대한 추론 중 정확한 신뢰도 점수를 가져야 한다. 
실제로 그림 7에서 볼 수 있듯이 TL과 CL 모델 모두 각 등급에 대해 동일한 최대 신뢰 점수를 가지면서도 4개 등급 모두를 정확하게 분류한다. 
주황색 직사각형은 추론 중에 어떤 클래스가 선택되었는지 나타내고, 신뢰도는 각 버튼 아래에 나타난다.   

New Instance 시나리오에서는 그림 8에서와 같이 CL 모델이 완벽한 점수로 첫번째 인스턴스를 구분하는 데에 문제가 없음을 볼 수 있다.
반면에 TL 모델은 훈련 중에 사용할 수 있는 모든 새로운 인스턴스 데이터가 있음에도 불구하고 이미 약간 줄어든 신뢰도 점수로 망각에 대한 증거를 보이고 있다.
신규 인스턴스 1개만 도입하면 효과는 미미하지만, 향후 신규 인스턴스가 도입됨에 따라 TL 모델의 성능이 지속적으로 저하될 것으로 예상한다.

CL 모델의 실제 실용성과 성능을 나타내는 실험은 New Classes 시나리오로, 그림 9에 나타난다. 
CL 모델의 경우 네개의 클래스를 완벽한 점수로 모두 분류한다.
하지만 TL 모델의 경우 극적으로 분류를 실패하고, 하나의 클래스만 분류할 수 있다. 
특히 마지막에 추가한 클래스인 공책만 올바르게 분류한다. 
이는 임베디드 장치에서 TL 모델을 사용하여 현실적인 학습을 진행할 때의 파괴적 망각이 발생한다는 명백한 증거이다.

### 4.2 Testing Continual Learning Under Non-Ideal Conditions
우리는 이미 TF Lite의 연속학습을 위한 확장을 한 모델을 임베디드 시스템에 배치했을 때, 보다 현실적인 시나리오에서의 장점에 대해 나타냈다.
다음 단계는 CL 모델이 비이상적인 상황에서도 범용적인지를 시험하는 것이다.
이런 이유로, 우리는 모델을 그림 6에 나타난 네가지 클래스를 통해 학습시켰다.
이전의 실험과 다르게, 각 클래스에 다양한 특성과 난이도를 가진 고유한 70개의 샘플을 수집했다.
특히, 각 샘플마다 깊이, 밝기, 배경, 방향 등이 지속적으로 변경되고, 개체가 흐릿하거나 잘릴 수 있고, 고유한 특성이 가려질 수 있다.
샘플 수집과 점진적인 학습에 대한 비디오는 [링크](https://www.youtube.com/watch?v=mVI1ob55vZw&)에서 찾을 수 있다.   

이런 현실적인 조건에서 테스트를 징행할 때, CL 모델은 여전히 물체를 올바르게 분류한다.
특히 정확도 점수는 리모컨과 병에서 0.85~1, 컵은 0.75~1, 안경은 항상 1이었다. 
이런 일반적인 우수성에도 불구하고, CL 모델은 아래 상황들에 대해서 올바른 분류를 수행하지 못한다.
- 리모컨이 버튼이 보이지 않게 뒤집어 졌을 때 (키 특성이 감춰졌을 때)
- 컵의 손잡이가 보이지 않을 때 (잘리거나 흐릿할 때)
- 병의 바닥만이 보이고, 따라서 뚜껑이 보이지 않을 때 (키 특성이 감춰졌을 때)

또한, 학습이 실패할 때 마다 마지막에 학습된 클래스가 기본 값으로 설정되는 것 또한 흥미롭다. 이 경우에는 안경이 마지막에 학습한 클래스이다.
이는 이후의 작업에서 학습 속도를 조정하거나, 학습 마지막 단계에 replay 하는 방식 대신 새로운 샘플을 replay 버퍼가 학습 중에 섞어서 학습하는 등의 방법을 통해 완화 될 것이다. 

## 5. Conclusion and Future Work 
이 논문에서, 우리가 직접 구현한 어플리케이션과 CORe50 벤치마크를 통해 현재 TF Lite의 전이 학습이 사실적이고 연속적인 학습에 대한 처리 능력이 없음을 증명했다. 
이 문제를 해결하기 위해 우리는 TF Lite의 라이브러리를 현재의 TL 모델에 간단한 replay 버퍼를 추가하는 방법을 통해 연속학습이 가능하도록 확장했다.
예제 프로그램의 소스코드는 개발자들이 연속 학습을 그들의 어플리케이션에 통합하고, TF Lite 를 통한 개발을 촉진시키기 위해 오픈소스로 공개한다.   

앞으로 모델의 head 신경망을 변경하고 여러 최신 알고리즘을 사용하여 모델을 테스트하는 방법으로 TF Lite의 한계 내에서 정규화, 모듈화, 보다 정교한 리허설 기법 등 추가적인 지속적 학습 방법론을 구현하는 데에 집중할 것이다.
우리는 더 많은 레이어를 head 에 추가하고, 표현을 조정할 수 있도록 신경망을 더 복잡하게 하는 실험을 진행할 것이다. 
마지막으로, 우리는 이 분야에 대한 연구를 촉진시키기 위해 안드로이드를 위한 연속학습 TF API를 구현할 예정이다. 
